{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "sHzCO7o3o52i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "SZLJSu1jhtbC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip show imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX5Kr1tRNxpR",
        "outputId": "9da1e31e-a5b7-44a8-f6b8-6f298422bf1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: imbalanced-learn\n",
            "Version: 0.10.1\n",
            "Summary: Toolbox for imbalanced dataset in machine learning.\n",
            "Home-page: https://github.com/scikit-learn-contrib/imbalanced-learn\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: joblib, numpy, scikit-learn, scipy, threadpoolctl\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRwPTxX6MJhr",
        "outputId": "b0e858cc-5d43-402d-804c-2fb227ea8f44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: scikit-learn\n",
            "Version: 1.2.2\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: http://scikit-learn.org\n",
            "Author: \n",
            "Author-email: \n",
            "License: new BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: joblib, numpy, scipy, threadpoolctl\n",
            "Required-by: bigframes, fastai, imbalanced-learn, librosa, mlxtend, qudida, sklearn-pandas, yellowbrick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "ORSkAPa_PXsh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-ua1xJOBR62",
        "outputId": "394a1dfc-e834-4a08-93b8-27ada86fb8f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cvpQLqe4MzUW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/NLPFinalProject/Model Implementation/imbalancedtask1.csv')"
      ],
      "metadata": {
        "id": "-kPFrfGxhfLi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text_lemmatize(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['chat1_processed'] = data['chat1'].apply(preprocess_text_lemmatize)\n",
        "data['chat2_processed'] = data['chat2'].apply(preprocess_text_lemmatize)\n",
        "\n",
        "# Using a more complex model like XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Extract features from the preprocessed text data\n",
        "X = vectorizer.fit_transform(data['chat1_processed'] + ' ' + data['chat2_processed'])\n",
        "\n",
        "import pickle\n",
        "with open('vectorizer.pkl', 'wb') as file:\n",
        "    pickle.dump(vectorizer, file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiT5JNye0fLV",
        "outputId": "750953f0-b42e-4ac0-f487-97f1a42d1027"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using SMOTE for oversampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Perform oversampling before splitting into training and test sets\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, data['label'])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use GridSearchCV for hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.5,],\n",
        "    'colsample_bytree': [0.5],\n",
        "    'n_estimators' : [100],\n",
        "    'objective': ['binary:logistic']\n",
        "}\n",
        "\n",
        "# Initialize the classifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='f1', verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best parameters: \", best_params)\n",
        "\n",
        "# Train a XGBClassifier model on the training set with the best parameters\n",
        "xgb_best = XGBClassifier(**best_params)\n",
        "xgb_best.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = xgb_best.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
        "print('Precision:', precision_score(y_test, y_pred_xgb))\n",
        "print('Recall:', recall_score(y_test, y_pred_xgb))\n",
        "print('F1 score:', f1_score(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks3-2km7b4ra",
        "outputId": "dd1b72e9-9e30-4750-e02c-cda4a52ff5d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Best parameters:  {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'objective': 'binary:logistic', 'subsample': 0.5}\n",
            "Accuracy: 0.896969696969697\n",
            "Precision: 0.9283489096573209\n",
            "Recall: 0.8688046647230321\n",
            "F1 score: 0.8975903614457832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBDt_cxl5CL5",
        "outputId": "5a958919-5046-42aa-b6e6-e73edb5becd7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2JfvxHX4fJh",
        "outputId": "3533fe43-afc4-4c89-9089-81d82925ecb7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<660x42609 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 238924 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFsLKxrQhgQR",
        "outputId": "c438ab2c-04c9-4177-a017-66daf0c35336"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      0.93      0.90       317\n",
            "        True       0.93      0.87      0.90       343\n",
            "\n",
            "    accuracy                           0.90       660\n",
            "   macro avg       0.90      0.90      0.90       660\n",
            "weighted avg       0.90      0.90      0.90       660\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lSSGDCV2WUe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'XBBOOST_Imbalanced.pkl'\n",
        "pickle.dump(xgb_best, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "-reUaV1R3hgK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text input\n",
        "text_input = \"china and japan's budding relationship in the time of coronavirus. the virus has been linked to a series deaths from pneumonia since last year but no cases have yet shown up outside asia or even within china. it is thought that it could be spread by people who come into contact with infected animals such as monkeys at zoos around asia. but experts say they are still trying determine how far this disease can spread. they said there was little evidence so far, however, suggesting any link between humans being bitten while on holiday abroad and, say, an outbreak here. and many tourists visiting hong kong were not infected. a chinese tourist died after returning home earlier than expected. in japan, where two japanese men fell ill shortly before christmas, authorities ordered all visitors staying over for christmas holidays away until further notice. some hotels also closed their doors early because guests had already left. there appeared today only one case among those infected, which occurred when someone returned late saturday night -- about eight hours later - bringing back his own travel bag. he did not, though, show symptoms himself. authorities believe he contracted sars during overseas travel. at least three other travelers came down sick there. one man died, another recovered fully, according tokyo hospitals. all five patients worked overseas, including four americans working abroad. another american woman got sick. officials don't know if she caught it. japan will test more hotel rooms next week ahead of, possibly, additional cases. most foreign passengers arriving here stay overnight anyway, officials said. we do everything we can, yoshiaki okamoto, head doctor general told reporters. we're doing our best. health minister yukio edano onaga visited shanghai today. his visit comes amid concerns china's new measures against possible outbreak. government ban announced friday morning flight cancellations due partly blamed flu epidemic scare caused flights canceled yesterday. mr. offered yesterday afternoon beijing airport cancellation yesterday, canceling some airlines cancelled hundreds left thousands stranded overseas. on thursday, air traffic delays delayed arrival tuesday, local media reports suggest few days ago cancel flights, leaving millions without explanation. two u.s. secretary general motors chief executive says airline executives made public health official announcement monday morning. with most likely would like safety issues affecting united states department spokesman called tuesday may 26 march 8 a.m. flight 370 million tickets canceled. even though boeing 787 scheduled departure april 4 p.m. this week, delta air france airlines jet planes grounded its main carrier flies out 1 june 6, july 21 september 11, plane crash involving korean airlines. what you can't fly feb. 19 august 15, 2009 world trade center san francisco airport new york city international airport's arrival. passengers wait list february 6 billion dollar trade center boston area 2 day 15 years ago. if anyone sent washington 11 december 12, 2003 america must now available january 2005 10 miles per capita economic crisis 5 november 29 october 10, sept. 11. where does not. as\"\n",
        "# Preprocess the text input using the same preprocessing function\n",
        "text_input_processed = preprocess_text_lemmatize(text_input)\n",
        "\n",
        "# Vectorize the preprocessed text input\n",
        "text_input_vectorized = vectorizer.transform([text_input_processed])\n",
        "\n",
        "# Use the trained XGBoost model to make a prediction\n",
        "prediction = xgb_best.predict(text_input_vectorized)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Prediction for the text input:\", prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq8YuYCSCjKE",
        "outputId": "7b00ce11-27bb-4108-e9bf-27a3e86b312c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for the text input: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQL94gq8DKZO",
        "outputId": "00cc38c9-769d-4ef0-f1e7-cdb03bec7e67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['chat1'][5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "EuurKN53CrBW",
        "outputId": "5e9ed70a-4655-4750-d3ee-195618adae18"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"china and japan's budding relationship in the time of coronavirus. the virus has been linked to a series deaths from pneumonia since last year but no cases have yet shown up outside asia or even within china. it is thought that it could be spread by people who come into contact with infected animals such as monkeys at zoos around asia. but experts say they are still trying determine how far this disease can spread. they said there was little evidence so far, however, suggesting any link between humans being bitten while on holiday abroad and, say, an outbreak here. and many tourists visiting hong kong were not infected. a chinese tourist died after returning home earlier than expected. in japan, where two japanese men fell ill shortly before christmas, authorities ordered all visitors staying over for christmas holidays away until further notice. some hotels also closed their doors early because guests had already left. there appeared today only one case among those infected, which occurred when someone returned late saturday night -- about eight hours later - bringing back his own travel bag. he did not, though, show symptoms himself. authorities believe he contracted sars during overseas travel. at least three other travelers came down sick there. one man died, another recovered fully, according tokyo hospitals. all five patients worked overseas, including four americans working abroad. another american woman got sick. officials don't know if she caught it. japan will test more hotel rooms next week ahead of, possibly, additional cases. most foreign passengers arriving here stay overnight anyway, officials said. we do everything we can, yoshiaki okamoto, head doctor general told reporters. we're doing our best. health minister yukio edano onaga visited shanghai today. his visit comes amid concerns china's new measures against possible outbreak. government ban announced friday morning flight cancellations due partly blamed flu epidemic scare caused flights canceled yesterday. mr. offered yesterday afternoon beijing airport cancellation yesterday, canceling some airlines cancelled hundreds left thousands stranded overseas. on thursday, air traffic delays delayed arrival tuesday, local media reports suggest few days ago cancel flights, leaving millions without explanation. two u.s. secretary general motors chief executive says airline executives made public health official announcement monday morning. with most likely would like safety issues affecting united states department spokesman called tuesday may 26 march 8 a.m. flight 370 million tickets canceled. even though boeing 787 scheduled departure april 4 p.m. this week, delta air france airlines jet planes grounded its main carrier flies out 1 june 6, july 21 september 11, plane crash involving korean airlines. what you can't fly feb. 19 august 15, 2009 world trade center san francisco airport new york city international airport's arrival. passengers wait list february 6 billion dollar trade center boston area 2 day 15 years ago. if anyone sent washington 11 december 12, 2003 america must now available january 2005 10 miles per capita economic crisis 5 november 29 october 10, sept. 11. where does not. as\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dbQzW3dCwjd"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}